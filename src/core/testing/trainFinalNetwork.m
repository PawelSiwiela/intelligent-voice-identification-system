function net = trainFinalNetwork(X, Y, golden_params)
% Trenuje finalnÄ… sieÄ‡ z Golden Parameters Z OKNEM TRENOWANIA

logInfo('ğŸ† Trenowanie FINALNEJ sieci z Golden Parameters...');
logInfo('   ğŸ§  Architektura: %s', mat2str(golden_params.hidden_layers));
logInfo('   âš™ï¸ Funkcja treningu: %s', golden_params.train_function);
logInfo('   ğŸ“ˆ Learning rate: %.4f', golden_params.learning_rate);

% ===== TWORZENIE SIECI =====
net = patternnet(golden_params.hidden_layers, golden_params.train_function);

% ===== USTAWIENIA TRENINGU Z OKNEM! =====
net.trainParam.showWindow = true;         % âœ… WÅÄ„CZ okno trenowania!
net.trainParam.showCommandLine = false;    % âœ… WÅÄ„CZ command line
net.plotFcns = {'plotperform', 'plottrainstate', 'plotconfusion', 'plotroc'};
% Parametry trenowania z Golden Parameters
net.trainParam.lr = golden_params.learning_rate;
net.trainParam.epochs = golden_params.epochs;

% Funkcja aktywacji
for i = 1:length(net.layers)
    if i < length(net.layers)
        net.layers{i}.transferFcn = golden_params.activation_function;
    end
end

% ===== PODZIAÅ DANYCH =====
net.divideParam.trainRatio = 0.8;
net.divideParam.valRatio = 0.15;
net.divideParam.testRatio = 0.05;

% ===== TRENOWANIE Z OKNEM =====
logInfo('ğŸš€ Rozpoczynam trenowanie finalnej sieci...');
logInfo('ğŸ“± OKNO TRENOWANIA zostanie wyÅ›wietlone!');

try
    [net, ~] = train(net, X', Y');
    logSuccess('âœ… Finalna sieÄ‡ wytrenowana pomyÅ›lnie z oknem!');
    
catch ME
    logError('âŒ BÅ‚Ä…d trenowania finalnej sieci: %s', ME.message);
    rethrow(ME);
end

end